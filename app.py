import streamlit as st
import geopandas as gpd
import pandas as pd
from shapely.geometry import Polygon
import folium
from streamlit_folium import st_folium
import zipfile
import os
import tempfile

st.set_page_config(page_title="üß≠ Contr√¥le Qualit√© Cadastral", layout="wide")

lang = st.selectbox("üåê Choisir une langue / Choose a language", ["Fran√ßais", "English"])

texts = {
    "Fran√ßais": {
        "title": "üß≠ Contr√¥le Qualit√© de Shapefile Cadastral",
        "upload": "üìÇ Importer un fichier ZIP contenant un shapefile",
        "error_shp": "Aucun fichier .shp trouv√© dans l'archive.",
        "summary": "üìä Synth√®se des erreurs d√©tect√©es",
        "map": "üó∫Ô∏è Carte des superpositions d√©tect√©es",
        "download": "üì• T√©l√©charger les rapports",
        "excel_button": "üì§ T√©l√©charger Excel"
    },
    "English": {
        "title": "üß≠ Cadastral Shapefile Quality Check",
        "upload": "üìÇ Upload a ZIP file containing the shapefile",
        "error_shp": "No .shp file found in the archive.",
        "summary": "üìä Summary of detected errors",
        "map": "üó∫Ô∏è Map of detected overlaps",
        "download": "üì• Download reports",
        "excel_button": "üì§ Download Excel"
    }
}

txt = texts[lang]

st.title(txt["title"])
uploaded_file = st.file_uploader(txt["upload"], type="zip")

if uploaded_file:
    with tempfile.TemporaryDirectory() as tmpdir:
        zip_path = os.path.join(tmpdir, "uploaded.zip")
        with open(zip_path, "wb") as f:
            f.write(uploaded_file.read())
        with zipfile.ZipFile(zip_path, "r") as zip_ref:
            zip_ref.extractall(tmpdir)

        shp_files = [os.path.join(tmpdir, f) for f in os.listdir(tmpdir) if f.endswith(".shp")]
        if not shp_files:
            st.error(txt["error_shp"])
        else:
            shapefile_path = shp_files[0]
            df = gpd.read_file(shapefile_path)
            crs = df.crs

            for field in ["Date_enq", "Date_naiss", "Date_deliv", "Dat_delivX", "Dat_trans1", "Dat_trans2"]:
                if field in df.columns:
                    df[field] = pd.to_datetime(df[field], errors="coerce")

            df_valid = df[df["Num_piece"].notna() & ~df["Num_piece"].isin(["Neant", "N√©ant", "CNI perdu"])]
            df_doublons = df_valid[df_valid["Num_piece"].duplicated(keep=False)]
            df_len_err = df_valid[df_valid["Num_piece"].str.len().fillna(0).astype(int).between(13, 15) == False]
            df_empty = df[df["Nom"].isna() | df["Prenom"].isna() | df["Nat"].isna() | df["Lieu_naiss"].isna()]
            df_incoh = df_valid.groupby("Num_piece").filter(lambda x: x[["Nom", "Prenom"]].nunique().sum() > 2)

            overlaps = []
            for i, a in df.iterrows():
                for j, b in df.iloc[i+1:].iterrows():
                    if a.geometry.intersects(b.geometry):
                        inter = a.geometry.intersection(b.geometry)
                        if inter.geom_type == 'Polygon' and inter.area > 0.1:
                            overlaps.append({
                                "parcelle_1": a.get("Num_parcel", i),
                                "parcelle_2": b.get("Num_parcel", j),
                                "area_m2": inter.area,
                                "geom": inter
                            })
            df_overlaps = gpd.GeoDataFrame(overlaps, geometry="geom", crs=crs)

            summary = pd.DataFrame({
                "Anomalie" if lang == "Fran√ßais" else "Issue": [
                    "Doublons Num_piece" if lang == "Fran√ßais" else "Duplicate ID",
                    "Longueur Num_piece invalide" if lang == "Fran√ßais" else "Invalid ID length",
                    "Superpositions g√©om√©triques" if lang == "Fran√ßais" else "Geometric overlaps",
                    "Champs critiques vides" if lang == "Fran√ßais" else "Missing critical fields",
                    "Noms incoh√©rents" if lang == "Fran√ßais" else "Conflicting names"
                ],
                "Nombre" if lang == "Fran√ßais" else "Count": [
                    len(df_doublons), len(df_len_err), len(df_overlaps), len(df_empty), len(df_incoh)
                ]
            })

            st.subheader(txt["summary"])
            st.dataframe(summary)

            if not df_overlaps.empty:
                m = folium.Map(location=[
                    df_overlaps.geometry.centroid.y.mean(),
                    df_overlaps.geometry.centroid.x.mean()], zoom_start=13)
                for _, row in df_overlaps.iterrows():
                    geo_json = gpd.GeoSeries(row["geom"]).simplify(0.001).to_json()
                    folium.GeoJson(data=geo_json, style_function=lambda x: {"color": "red"}).add_to(m)
                st.subheader(txt["map"])
                st_folium(m, width=1000, height=500)

            if st.button(txt["download"]):
                with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_xls:
                    with pd.ExcelWriter(tmp_xls.name, engine="xlsxwriter") as writer:
                        summary.to_excel(writer, sheet_name="Synth√®se", index=False)
                        df_doublons.to_excel(writer, sheet_name="Doublons", index=False)
                        df_len_err.to_excel(writer, sheet_name="Longueur", index=False)
                        df_empty.to_excel(writer, sheet_name="Champs_vides", index=False)
                        df_incoh.to_excel(writer, sheet_name="Incoh√©rences", index=False)
                        df_overlaps.drop(columns="geom").to_excel(writer, sheet_name="Superpositions", index=False)
                    st.download_button(txt["excel_button"], tmp_xls.read(), file_name="rapport_qualite.xlsx")
